"""
pipeline_graph.py
-----------------
LangGraph íŒŒì´í”„ë¼ì¸ (parse_html.py ì—°ê²° ë²„ì „)

ê·¸ë˜í”„(ê¸°ë³¸):
  get_library_portal â†’ search_book â†’ parse_html â†’ END

ë‹¨ì¶• ê²½ë¡œ:
  ì €ì¥ëœ HTML ê²½ë¡œ(html_path ë˜ëŠ” TEST_HTML)ê°€ ì£¼ì–´ì§€ë©´ ê·¸ë˜í”„ë¥¼ ê±´ë„ˆë›°ê³ 
  ê³§ë°”ë¡œ parse_htmlë§Œ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ ë°˜í™˜í•œë‹¤.

ì—­í• :
- get_library_portal: catalog_index.yamlì—ì„œ í•´ë‹¹ êµ¬(place)ì˜ í¬í„¸/ì¹´íƒˆë¡œê·¸ í™ˆ URLì„ ì°¾ìŒ
- search_book: ì œëª©ìœ¼ë¡œ ê²€ìƒ‰í•˜ê³ , ê²°ê³¼ í˜ì´ì§€ë¥¼ HTMLë¡œ ì €ì¥(saved_html_path ë“±)
- parse_html: ì €ì¥ëœ HTMLì„ BeautifulSoupìœ¼ë¡œ DOM ì§ë… íŒŒì‹± â†’ ìµœì†Œ í•„ìˆ˜ í•„ë“œ(title, library, status_raw, available)

CLI ì˜ˆì‹œ:
  PYTHONPATH=00_src python -m graph.pipeline_graph
"""

from __future__ import annotations
from typing import Dict, Any
import pprint
import os
from datetime import datetime
import argparse

# LangGraph ê¸°ë³¸ ì»´í¬ë„ŒíŠ¸
from langgraph.graph import StateGraph, END

# ìš°ë¦¬ê°€ ë§Œë“  ë…¸ë“œ í•¨ìˆ˜
from nodes.get_library_portal import get_library_portal
from nodes.search_book import search_book
from nodes.parse_html import parse_html


def build_graph():
    """
    ê·¸ë˜í”„: get_library_portal â†’ search_book â†’ parse_html â†’ END
    """
    graph = StateGraph(dict)  # ìƒíƒœëŠ” ë‹¨ìˆœíˆ dictë¡œ ì‚¬ìš©

    graph.add_node("get_library_portal", get_library_portal)
    graph.add_node("search_book", search_book)
    graph.add_node("parse_html", parse_html)

    graph.set_entry_point("get_library_portal")
    graph.add_edge("get_library_portal", "search_book")
    graph.add_edge("search_book", "parse_html")
    graph.add_edge("parse_html", END)

    return graph.compile()

app = build_graph()


def run_once(place: str, title: str, html_path: str | None = None) -> Dict[str, Any]:
    """
    ê·¸ë˜í”„ë¥¼ í•œ ë²ˆ ì‹¤í–‰í•œë‹¤.

    ì…ë ¥:
      - place: 'gangnam' | 'songpa' | 'seocho' ... ë“±
      - title: ì±… ì œëª©(ê²€ìƒ‰ì–´)
      - html_path: (ì„ íƒ) ì´ë¯¸ ì €ì¥ëœ HTML íŒŒì¼ë§Œ íŒŒì‹±í•˜ê³  ì‹¶ì„ ë•Œ ì§€ì •

    ì¶œë ¥: ìµœì¢… state(dict)
    """
    initial_state: Dict[str, Any] = {"place": place, "title": title}

    # ---- [ADDED] Set default parsed-output paths so parse_html can save in graph mode ----
    # Environment overrides:
    env_out_jsonl = os.environ.get("TEST_OUT_JSONL")
    env_out_json = os.environ.get("TEST_OUT_JSON")

    # Default path: 00_src/data/parsed/{YYYY-MM-DD}/{place}_results.jsonl
    date_str = datetime.now().strftime("%Y-%m-%d")
    default_parsed_dir = os.path.join("00_src", "data", "parsed", date_str)
    try:
        os.makedirs(default_parsed_dir, exist_ok=True)
    except Exception:
        # If directory creation fails, parse_html will still run without saving.
        pass

    default_jsonl = os.path.join(default_parsed_dir, f"{place}_results.jsonl")
    default_json = os.path.join(default_parsed_dir, f"{place}_results.json")

    # Apply overrides if provided
    if env_out_jsonl:
        initial_state["out_jsonl"] = env_out_jsonl
    else:
        initial_state["out_jsonl"] = default_jsonl

    if env_out_json:
        initial_state["out_json"] = env_out_json
    else:
        initial_state["out_json"] = default_json
    # ---- [ADDED END] ----

    # ì €ì¥ëœ HTMLì´ ìˆìœ¼ë©´ ê·¸ë˜í”„ë¥¼ ê±´ë„ˆë›°ê³  ë°”ë¡œ íŒŒì‹± ë…¸ë“œë¥¼ í˜¸ì¶œí•œë‹¤.
    # (ê²€ìƒ‰/íƒìƒ‰ì„ ìƒëµí•˜ì—¬ parse_htmlë§Œ ì‹¤í–‰)
    if html_path:
        initial_state["saved_html_path"] = html_path
        # Ensure one-off parse also saves to the same configured paths
        initial_state.setdefault("out_jsonl", initial_state.get("out_jsonl"))
        initial_state.setdefault("out_json", initial_state.get("out_json"))
        # parse_htmlì€ ìƒíƒœ dictë¥¼ ì…ë ¥ë°›ì•„ ë™ì¼ dictë¥¼ ë°˜í™˜í•˜ë„ë¡ ì„¤ê³„ë¨
        return parse_html(initial_state)

    # ì €ì¥ëœ HTMLì´ ì—†ìœ¼ë©´ ì •ìƒ ê·¸ë˜í”„ ì‹¤í–‰ (get_library_portal â†’ search_book â†’ parse_html)
    result_state = app.invoke(initial_state)
    return result_state


if __name__ == "__main__":
    # ------------------------------------------------------------------
    # CLI íŒŒì„œ: í™˜ê²½ë³€ìˆ˜ + CLI ë™ì‹œ ì§€ì› (CLIê°€ ìš°ì„ )
    #   ì˜ˆ)
    #   PYTHONPATH=00_src python -m graph.pipeline_graph \
    #     --place gangnam \
    #     --title "ì–´ë¦° ì™•ì" \
    #     --html-override --html-path 00_src/data/raw/2025-10-28/gangnam_1761660636_results.html \
    #     --out-jsonl 00_src/data/parsed/2025-10-28/gangnam_results.jsonl \
    #     --out-json  00_src/data/parsed/2025-10-28/gangnam_results.json
    # ------------------------------------------------------------------
    parser = argparse.ArgumentParser(description="Library search â†’ HTML save â†’ JSON/JSONL parse pipeline")
    parser.add_argument("--place", type=str, help="ì˜ˆ: gangnam | songpa | seocho ...")
    parser.add_argument("--title", type=str, help="ê²€ìƒ‰ì–´(ë„ì„œëª…)")
    parser.add_argument("--html-override", action="store_true", help="ë¸Œë¼ìš°ì € ê²€ìƒ‰ ìƒëµ, ì €ì¥ëœ HTMLë§Œ íŒŒì‹±")
    parser.add_argument("--html-path", type=str, help="ì €ì¥ëœ HTML ê²½ë¡œ (overrideì™€ í•¨ê»˜ ì‚¬ìš© ê¶Œì¥)")
    parser.add_argument("--out-jsonl", type=str, help="JSONL ì €ì¥ ê²½ë¡œ")
    parser.add_argument("--out-json", type=str, help="JSON ì €ì¥ ê²½ë¡œ")
    args = parser.parse_args()

    # 1) place/title ìš°ì„ ìˆœìœ„: CLI > ENV > ê¸°ë³¸ê°’
    test_place = args.place or os.environ.get("TEST_PLACE", "seocho")
    test_title = args.title or os.environ.get("TEST_TITLE", "ì„¸ì´ë…¸ì˜ ê°€ë¥´ì¹¨")

    # 2) ì¶œë ¥ ê²½ë¡œ: CLIê°€ ì˜¤ë©´ ENVì— ì£¼ì…í•´ì„œ run_once ë‚´ë¶€ ë¡œì§ê³¼ ì •í•©
    if args.out_jsonl:
        os.environ["TEST_OUT_JSONL"] = args.out_jsonl
    if args.out_json:
        os.environ["TEST_OUT_JSON"] = args.out_json

    # 3) override ëª¨ë“œ: CLI --html-overrideê°€ ìˆìœ¼ë©´ --html-path ì‚¬ìš©
    #    (ì—†ìœ¼ë©´ ENV TEST_HTML ì‚¬ìš©; ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ë¸Œë¼ìš°ì € ê²€ìƒ‰)
    test_html = None
    if args.html_override and args.html_path:
        test_html = args.html_path
    else:
        test_html = os.environ.get("TEST_HTML")

    print(f"[pipeline_graph] run_once() with place={test_place}, title={test_title}, html_override={bool(test_html)}")

    # Show planned save paths for visibility (í™˜ê²½ë³€ìˆ˜ ë°˜ì˜ í›„ ê²½ë¡œ ê³„ì‚°)
    planned_date = datetime.now().strftime("%Y-%m-%d")
    planned_dir = os.path.join("00_src", "data", "parsed", planned_date)
    planned_jsonl = os.environ.get("TEST_OUT_JSONL", os.path.join(planned_dir, f"{test_place}_results.jsonl"))
    planned_json = os.environ.get("TEST_OUT_JSON", os.path.join(planned_dir, f"{test_place}_results.json"))
    print(f"[pipeline_graph] planned out_jsonl={planned_jsonl}")
    print(f"[pipeline_graph] planned out_json={planned_json}")

    out = run_once(test_place, test_title, html_path=test_html)

    print("\n[pipeline_graph] RESULT STATE")
    pprint.pprint(out)

    # ì•„ë˜ ì¶œë ¥ì€ í™•ì¸ìš©ì„. ë‚˜ì¤‘ì— ì‚­ì œí•  ê³„íš
    print("\n" + "="*80)
    print("[í•µì‹¬ ê²°ê³¼]")
    print("="*80)
    print(f"âœ“ ê²€ìƒ‰ ì„±ê³µ: {out.get('ok')}")
    print(f"âœ“ í˜ì´ì§€ URL: {out.get('page_url')}")
    
    # ë‹¤ì¤‘ í˜ì´ì§€ ì¶œë ¥
    total_pages = out.get('total_pages', 1)
    saved_html_paths = out.get('saved_html_paths', [out.get('saved_html_path')])
    saved_html_paths = [p for p in saved_html_paths if p]
    
    if total_pages > 1:
        print(f"âœ“ ì´ í˜ì´ì§€ ìˆ˜: {total_pages}ê°œ")
        for idx, path in enumerate(saved_html_paths, 1):
            print(f"  [{idx}] {path}")
    else:
        print(f"âœ“ HTML ì €ì¥ ê²½ë¡œ: {out.get('saved_html_path')}")

    # HTML í¬ê¸° í‘œì‹œ: ìƒíƒœì— ì—†ìœ¼ë©´ íŒŒì¼ í¬ê¸° ì§ì ‘ ê³„ì‚° ì‹œë„
    html_size = out.get("html_size", 0)
    if (not html_size) and out.get("saved_html_path"):
        try:
            html_size = os.path.getsize(out["saved_html_path"])
        except Exception:
            html_size = 0
    print(f"âœ“ HTML í¬ê¸°: {html_size:,} bytes")

    print(f"\nâœ“ íŒŒì‹± ì„±ê³µ: {out.get('parse_success')}")
    if out.get('parse_error'):
        print(f"âœ“ íŒŒì‹± ì—ëŸ¬: {out.get('parse_error')}")

    # Print saved artifact locations if any
    saved_artifacts = out.get("saved")
    if saved_artifacts:
        print("\nâœ“ ì €ì¥ëœ ì‚°ì¶œë¬¼:")
        for kind, path in saved_artifacts:
            print(f"   - {kind}: {path}")
    else:
        # Fallback: show planned paths (may be used if parse_html handled saving silently)
        if out.get("out_jsonl") or out.get("out_json"):
            print("\nâœ“ (ì°¸ê³ ) ì €ì¥ ê²½ë¡œ(ê³„íš):")
            if out.get("out_jsonl"):
                print(f"   - jsonl: {out['out_jsonl']}")
            if out.get("out_json"):
                print(f"   - json:  {out['out_json']}")

    parsed_books = out.get('parsed_books', [])
    if parsed_books:
        print(f"\nğŸ“š ë°œê²¬ëœ ë„ì„œ: {len(parsed_books)}ê±´")
        print("-"*80)
        for idx, book in enumerate(parsed_books[:10], 1):
            title = book.get('title') or 'N/A'
            publisher = book.get('publisher') or 'N/A'
            year = book.get('year') or 'N/A'
            library = book.get('library') or 'N/A'
            room = book.get('room') or 'N/A'
            callno = book.get('call_number') or 'N/A'
            status_raw = book.get('status_raw') or 'N/A'
            available = book.get('available', False)

            print(f"\n[{idx}] {title}")
            print(f"    ì¶œíŒì‚¬: {publisher} ({year})")
            print(f"    ë„ì„œê´€: {library}")
            print(f"    ìë£Œì‹¤: {room}")
            print(f"    ì²­êµ¬ê¸°í˜¸: {callno}")
            print(f"    ìƒíƒœ: {'âœ… ëŒ€ì¶œê°€ëŠ¥' if available else 'âŒ ëŒ€ì¶œë¶ˆê°€'}  | raw='{status_raw}'")

            if book.get('reserve_count') is not None:
                print(f"    ì˜ˆì•½: {book['reserve_count']}")
            if book.get('due_date'):
                print(f"    ë°˜ë‚©ì˜ˆì •ì¼: {book['due_date']}")
    else:
        print("\nğŸ“š BeautifulSoup íŒŒì‹± ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤ (DOM ëª¨ë“œ).")
        print("    â†’ ì €ì¥ëœ HTMLì´ ë Œë”ë§ ì „ ìŠ¤ëƒ…ìƒ·ì´ê±°ë‚˜, DOM êµ¬ì¡°ê°€ ë¹„í‘œì¤€ì¼ ìˆ˜ ìˆì–´ìš”.")

    print("\n" + "="*80)
