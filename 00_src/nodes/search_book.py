from __future__ import annotations
import os
from typing import Any, Dict, List, Optional
import urllib.parse as _urlparse  # ë„ë©”ì¸ ì¶”ì¶œìš©
from datetime import datetime
from pathlib import Path

# Agent ëª¨ë“œìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ (ë¡œì»¬ ë¸Œë¼ìš°ì € ì§ì ‘ ì œì–´)
try:
    from browser_use import Agent, ChatOpenAI, Browser  # type: ignore
except Exception:
    Agent = None  # type: ignore
    ChatOpenAI = None  # type: ignore
    Browser = None  # type: ignore

# .env ìë™ ë¡œë“œ(ìˆìœ¼ë©´)
try:
    from dotenv import load_dotenv  # type: ignore
    load_dotenv()
except Exception:
    pass

try:
    from browser_use_sdk import BrowserUseClient  # type: ignore
except Exception:
    BrowserUseClient = None  # ëŸ°íƒ€ì„ì— ë¯¸ì„¤ì¹˜ë©´ 'ì‹¤í–‰ ê³„íš'ë§Œ ë°˜í™˜í•˜ì—¬ ë””ë²„ê¹… ê°€ëŠ¥

SELECTORS_PATH = "00_src/configs/selectors.yaml"

# Quick SPA readiness keywords for Korean library sites
SPA_READY_KEYWORDS = ["ê²€ìƒ‰ê²°ê³¼", "ì†Œì¥", "ëŒ€ì¶œ", "ê´€ì‹¬ë„ì„œ", "ìƒì„¸ë³´ê¸°"]

def _build_browser_use_task(catalog_home_url: str, title: str, hint: Dict[str, Any], backoff: List[int]) -> str:
    """DOM ì‹ í˜¸ ê¸°ë°˜: ë³´ì´ë©´ ì¦‰ì‹œ ì§„í–‰, ë³´ì´ì§€ ì•Šìœ¼ë©´ ì¶©ë¶„íˆ ëŒ€ê¸° í›„ ì¢…ë£Œ."""
    return f"""
1) navigate to "{catalog_home_url}"
2) if a VISIBLE search input exists (placeholder/aria-label/label text includes: ê²€ìƒ‰|ë„ì„œ|ìë£Œ), DO NOT WAIT: focus it immediately.
   else wait up to 10s for SPA to load; if still hidden, STOP with no_results. DO NOT REFRESH.
3) type "{title}" and press Enter. if not submitted, click the search/ë‹ë³´ê¸° button ONCE (no repeats).
4) if URL changed OR the page contains any of [ê²€ìƒ‰ê²°ê³¼, ì†Œì¥, ëŒ€ì¶œ, ê±´], STOP immediately with success (done).
5) NEVER repeat the same action twice. at most 2 attempts TOTAL. do not open new tabs. do not save HTML.
"""

def search_book(state: Dict[str, Any]) -> Dict[str, Any]:
    """ë„ì„œê´€ í™ˆ ì´ë™ + ì´ˆê°„ë‹¨ ê²€ìƒ‰(ê²Œì´íŠ¸ë“œ LLM). ìº¡ì²˜ëŠ” í•˜ì§€ ì•ŠìŒ."""
    # í•µì‹¬ ì…ë ¥
    home = str(state.get("catalog_home_url", "")).strip()
    title = str(state.get("title", "")).strip()
    place = str(state.get("place", "")).strip()
    if not place:
        # fallback: try to infer later from saved filename; still keep non-empty token for downstream
        place = state["place"] = "unknown"
    if not home or not title:
        return {**state, "ok": False, "result_hint": "invalid_input", "page_url": None}

    # í…”ë ˆë©”íŠ¸ë¦¬ ë¹„í™œì„±(ë¶ˆí•„ìš” ë°±ì˜¤í”„ ë°©ì§€) - ëª¨ë“  ë³€ìˆ˜ ê°•ì œ ì„¤ì •
    os.environ["POSTHOG_DISABLED"] = "1"
    os.environ["ANONYMIZED_TELEMETRY"] = "false"
    os.environ["TELEMETRY_DISABLED"] = "1"
    os.environ["DO_NOT_TRACK"] = "1"

    # ë¸Œë¼ìš°ì € ì œí•œ: í™ˆ URLì—ì„œ ë„ë©”ì¸ ì¶”ì¶œ
    def _derive_allowed_from_home(url: str) -> List[str]:
        try:
            netloc = _urlparse.urlparse(url).netloc
            if netloc and "." in netloc:
                base = netloc.split(":")[0]
                parts = base.split(".")
                if len(parts) >= 2:
                    return [base, f"*.{'.'.join(parts[-2:])}"]
                return [base]
        except Exception:
            pass
        return ["*.go.kr", "*.or.kr"]  # fallback
    
    allowed = state.get("allowed_domains") or _derive_allowed_from_home(home)

    # ë¸Œë¼ìš°ì € ìƒì„±
    browser = None
    if Browser is not None:
        try:
            browser = Browser(
                headless=False,
                allowed_domains=allowed,
                window_size={"width": 1280, "height": 900},
                keep_alive=True,
                minimum_wait_page_load_time=0.5,
                wait_for_network_idle_page_load_time=0.8,
                wait_between_actions=0.2,
                highlight_elements=False,
            )
            print(f"[search_book] Browser ìƒì„± ì™„ë£Œ")
        except Exception as e:
            print(f"[search_book] âŒ Browser ìƒì„± ì‹¤íŒ¨: {e}")
            browser = None

    # LLM (ì†Œí˜• ëª¨ë¸)
    if Agent is None or ChatOpenAI is None:
        # ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¯¸ì„¤ì¹˜ ì‹œ ê³„íšë§Œ ë°˜í™˜
        task_preview = _build_browser_use_task(home, title, {}, [30, 60, 90])
        return {**state, "ok": False, "result_hint": "plan_only", "page_url": None, "log": ["browser_use Agent ë¯¸ì„¤ì¹˜"], "task_prompt": task_preview}
    llm = ChatOpenAI(model=state.get("llm_model", "gpt-5-mini"))

    # 1ë‹¨ê³„: ê·œì¹™ ê¸°ë°˜(ì•„ì£¼ ì§§ì€ íƒœìŠ¤í¬, max_steps=8)
    task_rules = _build_browser_use_task(home, title, {}, [30, 60, 90])
    agent_rules = Agent(task=task_rules, llm=llm, browser=browser) if browser else Agent(task=task_rules, llm=llm)

    import asyncio
    try:
        # asyncio ë‚´ì—ì„œ CDP/URL/HTML ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
        async def run_and_extract():
            history = await agent_rules.run(max_steps=int(state.get("max_steps_rules", 8)))
            
            # SPA ë¡œë”© ì™„ë£Œ ëŒ€ê¸°: ë„¤íŠ¸ì›Œí¬ ì•„ì´ë“¤ + ë³¸ë¬¸ í‚¤ì›Œë“œ ë“±ì¥ ëŒ€ê¸°(ìµœëŒ€ 10s)
            try:
                await browser.wait_for_network_idle(timeout=10000)
            except Exception:
                await asyncio.sleep(1.5)

            # ì¶”ê°€: ë³¸ë¬¸ì— ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²°ê³¼ í‚¤ì›Œë“œê°€ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€ í´ë§(ìµœëŒ€ 10s)
            ready = False
            for _ in range(20):  # 20 * 0.5s = 10s
                try:
                    eval_result = await browser.cdp_client.send.Runtime.evaluate(
                        params={
                            "expression": "document.body ? document.body.innerText : ''",
                            "returnByValue": True
                        },
                        session_id=browser.agent_focus.session_id
                    )
                    body_text = (eval_result.get("result", {}) or {}).get("value", "") or ""
                    if any(k in body_text for k in SPA_READY_KEYWORDS):
                        ready = True
                        break
                except Exception:
                    pass
                await asyncio.sleep(0.5)

            print(f"[search_book] SPA ë¡œë”© ëŒ€ê¸° ì™„ë£Œ ({'ì„±ê³µ' if ready else 'íƒ€ì„ì•„ì›ƒ'})")
            
            # ì¶”ê°€ ëŒ€ê¸°: ê²€ìƒ‰ ê²°ê³¼ ë°ì´í„°ê°€ ì™„ì „íˆ ë¡œë“œë  ì‹œê°„ í™•ë³´ (5ì´ˆ)
            if ready:
                print(f"[search_book] ê²€ìƒ‰ ê²°ê³¼ ë°ì´í„° ë¡œë”© ëŒ€ê¸° ì¤‘... (5ì´ˆ)")
                await asyncio.sleep(5)
            
            # CDP endpoint & page_url ì¶”ì¶œ
            page_url = None
            cdp = None
            
            if browser:
                try:
                    cdp = browser.cdp_url
                    print(f"[search_book] CDP: {cdp}")
                except Exception as e:
                    print(f"[search_book] CDP ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                
                try:
                    page_url = await browser.get_current_page_url()
                    print(f"[search_book] URL: {page_url}")
                except Exception as e:
                    print(f"[search_book] URL ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            
            # HTML ì¶”ì¶œ ë° ì €ì¥
            saved_path = None
            html_size = 0
            
            if browser and hasattr(browser, 'cdp_client') and browser.cdp_client:
                try:
                    print(f"[search_book] HTML ì¶”ì¶œ ì‹œì‘...")
                    result = await browser.cdp_client.send.Runtime.evaluate(
                        params={
                            "expression": "document.documentElement.outerHTML",
                            "returnByValue": True
                        },
                        session_id=browser.agent_focus.session_id
                    )
                    html_content = result.get("result", {}).get("value", "")
                    
                    if html_content:
                        # ì €ì¥ ê²½ë¡œ ìƒì„±
                        today = datetime.now().strftime("%Y-%m-%d")
                        timestamp = int(datetime.now().timestamp())
                        dir_path = f"00_src/data/raw/{today}"
                        os.makedirs(dir_path, exist_ok=True)
                        
                        filename = f"{place}_{timestamp}_results.html"
                        saved_path = os.path.join(dir_path, filename)
                        
                        # íŒŒì¼ ì €ì¥
                        with open(saved_path, "w", encoding="utf-8") as f:
                            f.write(html_content)
                        
                        # ë©”íƒ€ë°ì´í„° ì‚¬ì´ë“œì¹´ ì €ì¥(.meta.json)
                        try:
                            meta = {
                                "place": place,
                                "page_url": page_url,
                                "captured_at": datetime.now().isoformat(timespec="seconds"),
                                "cdp_endpoint": cdp
                            }
                            with open(saved_path + ".meta.json", "w", encoding="utf-8") as mf:
                                import json as _json
                                mf.write(_json.dumps(meta, ensure_ascii=False))
                        except Exception as _e:
                            print(f"[search_book] ë©”íƒ€ ì €ì¥ ê²½ê³ : {_e}")
                        
                        html_size = len(html_content)
                        print(f"[search_book] âœ… HTML ì €ì¥ ì™„ë£Œ (í˜ì´ì§€ 1): {saved_path} ({html_size:,} bytes)")
                    else:
                        print(f"[search_book] âš ï¸ HTML ë‚´ìš©ì´ ë¹„ì–´ìˆìŒ")
                        
                except Exception as e:
                    print(f"[search_book] âŒ HTML ì¶”ì¶œ/ì €ì¥ ì‹¤íŒ¨: {e}")
                    import traceback
                    traceback.print_exc()
            
            # ========== ë‹¤ì¤‘ í˜ì´ì§€ ì²˜ë¦¬: LLMì—ê²Œ 2í˜ì´ì§€ í´ë¦­ ìš”ì²­ ==========
            saved_html_paths = [saved_path]  # 1í˜ì´ì§€ ê²½ë¡œ ì €ì¥
            
            # 2í˜ì´ì§€ ì €ì¥ì„ ìœ„í•œ ë³€ìˆ˜ ì¤€ë¹„
            today = datetime.now().strftime("%Y-%m-%d")
            timestamp = int(datetime.now().timestamp())
            dir_path = Path(f"00_src/data/raw/{today}")
            
            if browser:
                try:
                    print(f"[search_book] ğŸ¤– LLMì—ê²Œ 2í˜ì´ì§€ í´ë¦­ ìš”ì²­...")
                    
                    # 2í˜ì´ì§€ í´ë¦­ íƒœìŠ¤í¬ (JavaScript ë§í¬ ëª…ì‹œ)
                    page2_task = """
Task: Click pagination button '2' to go to page 2.

Steps:
1) Scroll down slowly (2-3 pages) to find pagination area at the bottom
2) Look for a link or button with text '2' (it may be <a href="javascript:fnList(2);">2</a>)
3) Click that '2' link/button
4) Immediately call 'done' after clicking

Important: The '2' button is a JavaScript link, not a regular button. Look carefully.
Maximum 4 steps allowed.
"""
                    
                    page2_agent = Agent(
                        task=page2_task,
                        llm=llm,
                        browser=browser,
                        use_vision=False,
                        max_steps=4,  # ìŠ¤í¬ë¡¤ + í´ë¦­ ì—¬ìœ ìˆê²Œ
                    )
                    
                    print(f"[search_book] Agent ì‹¤í–‰ ì¤‘ (2í˜ì´ì§€ í´ë¦­)...")
                    page2_history = await page2_agent.run()
                    print(f"[search_book] âœ… 2í˜ì´ì§€ í´ë¦­ Agent ì™„ë£Œ (steps={len(page2_history)})")
                    
                    # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
                    print(f"[search_book] 2í˜ì´ì§€ ë¡œë”© ëŒ€ê¸° ì¤‘... (5ì´ˆ)")
                    await asyncio.sleep(5)
                    
                    # 2í˜ì´ì§€ HTML ì¶”ì¶œ
                    print(f"[search_book] 2í˜ì´ì§€ HTML ì¶”ì¶œ ì¤‘...")
                    page2_html = await browser.cdp_client.send.Runtime.evaluate(
                        params={
                            "expression": "document.documentElement.outerHTML",
                            "returnByValue": True
                        },
                        session_id=browser.agent_focus.session_id
                    )
                    page2_html_content = page2_html.get("result", {}).get("value", "")
                    
                    if page2_html_content and len(page2_html_content) > 1000:
                        # 2í˜ì´ì§€ íŒŒì¼ëª… ìƒì„±
                        page2_filename = f"{place}_{timestamp}_results_page2.html"
                        page2_path = dir_path / page2_filename
                        
                        # 2í˜ì´ì§€ HTML ì €ì¥
                        page2_path.write_text(page2_html_content, encoding="utf-8")
                        page2_size = len(page2_html_content)
                        print(f"[search_book] âœ… 2í˜ì´ì§€ HTML ì €ì¥ ì™„ë£Œ: {page2_path} ({page2_size:,} bytes)")
                        
                        saved_html_paths.append(str(page2_path))
                    else:
                        print(f"[search_book] âš ï¸ 2í˜ì´ì§€ HTML ì¶”ì¶œ ì‹¤íŒ¨ ë˜ëŠ” ë‚´ìš© ë¶€ì¡±")
                    
                except Exception as e:
                    print(f"[search_book] âš ï¸ 2í˜ì´ì§€ ì²˜ë¦¬ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
            
            # ë¸Œë¼ìš°ì € ì¢…ë£Œ (async ì»¨í…ìŠ¤íŠ¸ ë‚´ë¶€ì—ì„œ)
            if browser:
                try:
                    print(f"[search_book] ë¸Œë¼ìš°ì € ì¢…ë£Œ ì¤‘...")
                    await browser.stop()  # BrowserSessionì€ close() ëŒ€ì‹  stop() ì‚¬ìš©
                    print(f"[search_book] âœ… ë¸Œë¼ìš°ì € ì¢…ë£Œ ì™„ë£Œ")
                except Exception as e:
                    print(f"[search_book] âš ï¸ ë¸Œë¼ìš°ì € ì¢…ë£Œ ê²½ê³ : {e}")
            
            return history, page_url, cdp, saved_html_paths, html_size
        
        # asyncio ì‹¤í–‰
        history1, page_url, cdp_endpoint, saved_html_paths, html_size = asyncio.run(run_and_extract())
        
        total_pages = len(saved_html_paths)
        print(f"[search_book] ğŸ“Š ì´ {total_pages}ê°œ í˜ì´ì§€ HTML ì €ì¥ ì™„ë£Œ")
        
        return {
            **state, 
            "ok": True, 
            "result_hint": "results_detected", 
            "page_url": page_url, 
            "cdp_endpoint": cdp_endpoint, 
            "saved_html_path": saved_html_paths[0] if saved_html_paths else None,  # 1í˜ì´ì§€ ê²½ë¡œ (í•˜ìœ„ í˜¸í™˜)
            "saved_html_paths": saved_html_paths,  # ì „ì²´ í˜ì´ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            "total_pages": total_pages,
            "html_size": html_size, 
            "used_frame": None, 
            "markers": [], 
            "log": [f"rules_steps={len(history1) if isinstance(history1, list) else 'unknown'}"], 
            "place": place
        }
    except Exception as e1:
        # 2ë‹¨ê³„: ìœ ì—° íƒœìŠ¤í¬(í•œ ë²ˆë§Œ), max_steps=15
        task_llm = f"ìˆ˜ì •ëœ ì‹œë„: ìœ„ì™€ ë™ì¼í•˜ì§€ë§Œ ë‹¤ë¥¸ ê²½ë¡œë„ í—ˆìš©. ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ ì¢…ë£Œ.\n" + _build_browser_use_task(home, title, {}, [30, 60, 90])
        agent_llm = Agent(task=task_llm, llm=llm, browser=browser) if browser else Agent(task=task_llm, llm=llm)
        try:
            # asyncio ë‚´ì—ì„œ CDP/URL/HTML ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ (LLM ê²½ë¡œ)
            async def run_and_extract_llm():
                history = await agent_llm.run(max_steps=int(state.get("max_steps_llm", 15)))
                
                # SPA ë¡œë”© ì™„ë£Œ ëŒ€ê¸°: ë„¤íŠ¸ì›Œí¬ ì•„ì´ë“¤ + ë³¸ë¬¸ í‚¤ì›Œë“œ ë“±ì¥ ëŒ€ê¸°(ìµœëŒ€ 10s)
                try:
                    await browser.wait_for_network_idle(timeout=10000)
                except Exception:
                    await asyncio.sleep(1.5)

                # ì¶”ê°€: ë³¸ë¬¸ì— ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²°ê³¼ í‚¤ì›Œë“œê°€ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€ í´ë§(ìµœëŒ€ 10s)
                ready = False
                for _ in range(20):  # 20 * 0.5s = 10s
                    try:
                        eval_result = await browser.cdp_client.send.Runtime.evaluate(
                            params={
                                "expression": "document.body ? document.body.innerText : ''",
                                "returnByValue": True
                            },
                            session_id=browser.agent_focus.session_id
                        )
                        body_text = (eval_result.get("result", {}) or {}).get("value", "") or ""
                        if any(k in body_text for k in SPA_READY_KEYWORDS):
                            ready = True
                            break
                    except Exception:
                        pass
                    await asyncio.sleep(0.5)

                print(f"[search_book LLM] SPA ë¡œë”© ëŒ€ê¸° ì™„ë£Œ ({'ì„±ê³µ' if ready else 'íƒ€ì„ì•„ì›ƒ'})")
                
                # ì¶”ê°€ ëŒ€ê¸°: ê²€ìƒ‰ ê²°ê³¼ ë°ì´í„°ê°€ ì™„ì „íˆ ë¡œë“œë  ì‹œê°„ í™•ë³´ (5ì´ˆ)
                if ready:
                    print(f"[search_book LLM] ê²€ìƒ‰ ê²°ê³¼ ë°ì´í„° ë¡œë”© ëŒ€ê¸° ì¤‘... (5ì´ˆ)")
                    await asyncio.sleep(5)
                
                # CDP endpoint & page_url ì¶”ì¶œ
                page_url = None
                cdp = None
                
                if browser:
                    try:
                        cdp = browser.cdp_url
                        print(f"[search_book LLM] CDP: {cdp}")
                    except Exception as e:
                        print(f"[search_book LLM] CDP ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                    
                    try:
                        page_url = await browser.get_current_page_url()
                        print(f"[search_book LLM] URL: {page_url}")
                    except Exception as e:
                        print(f"[search_book LLM] URL ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                
                # HTML ì¶”ì¶œ ë° ì €ì¥
                saved_path = None
                html_size = 0
                
                if browser and hasattr(browser, 'cdp_client') and browser.cdp_client:
                    try:
                        print(f"[search_book LLM] HTML ì¶”ì¶œ ì‹œì‘...")
                        result = await browser.cdp_client.send.Runtime.evaluate(
                            params={
                                "expression": "document.documentElement.outerHTML",
                                "returnByValue": True
                            },
                            session_id=browser.agent_focus.session_id
                        )
                        html_content = result.get("result", {}).get("value", "")
                        
                        if html_content:
                            today = datetime.now().strftime("%Y-%m-%d")
                            timestamp = int(datetime.now().timestamp())
                            dir_path = f"00_src/data/raw/{today}"
                            os.makedirs(dir_path, exist_ok=True)
                            
                            filename = f"{place}_{timestamp}_results.html"
                            saved_path = os.path.join(dir_path, filename)
                            
                            with open(saved_path, "w", encoding="utf-8") as f:
                                f.write(html_content)
                            
                            # ë©”íƒ€ë°ì´í„° ì‚¬ì´ë“œì¹´ ì €ì¥(.meta.json)
                            try:
                                meta = {
                                    "place": place,
                                    "page_url": page_url,
                                    "captured_at": datetime.now().isoformat(timespec="seconds"),
                                    "cdp_endpoint": cdp
                                }
                                with open(saved_path + ".meta.json", "w", encoding="utf-8") as mf:
                                    import json as _json
                                    mf.write(_json.dumps(meta, ensure_ascii=False))
                            except Exception as _e:
                                print(f"[search_book LLM] ë©”íƒ€ ì €ì¥ ê²½ê³ : {_e}")
                            
                            html_size = len(html_content)
                            print(f"[search_book LLM] âœ… HTML ì €ì¥ ì™„ë£Œ: {saved_path} ({html_size:,} bytes)")
                        else:
                            print(f"[search_book LLM] âš ï¸ HTML ë‚´ìš©ì´ ë¹„ì–´ìˆìŒ")
                            
                    except Exception as e:
                        print(f"[search_book LLM] âŒ HTML ì¶”ì¶œ/ì €ì¥ ì‹¤íŒ¨: {e}")
                        import traceback
                        traceback.print_exc()
                
                # ë¸Œë¼ìš°ì € ì¢…ë£Œ (async ì»¨í…ìŠ¤íŠ¸ ë‚´ë¶€ì—ì„œ)
                if browser:
                    try:
                        print(f"[search_book] ë¸Œë¼ìš°ì € ì¢…ë£Œ ì¤‘...")
                        await browser.stop()  # BrowserSessionì€ close() ëŒ€ì‹  stop() ì‚¬ìš©
                        print(f"[search_book] âœ… ë¸Œë¼ìš°ì € ì¢…ë£Œ ì™„ë£Œ")
                    except Exception as e:
                        print(f"[search_book] âš ï¸ ë¸Œë¼ìš°ì € ì¢…ë£Œ ê²½ê³ : {e}")
                
                return history, page_url, cdp, saved_path, html_size
            
            history2, page_url, cdp_endpoint, saved_html_path, html_size = asyncio.run(run_and_extract_llm())
            
            return {**state, "ok": True, "result_hint": "results_detected", "page_url": page_url, "cdp_endpoint": cdp_endpoint, "saved_html_path": saved_html_path, "html_size": html_size, "used_frame": None, "markers": [], "log": [f"llm_steps={len(history2) if isinstance(history2, list) else 'unknown'}", str(e1)], "place": place}
        except Exception as e2:
            return {**state, "ok": False, "result_hint": "execution_error", "page_url": None, "cdp_endpoint": None, "saved_html_path": None, "html_size": 0, "used_frame": None, "markers": [], "log": ["rules_failed", str(e1), "llm_failed", str(e2)]}
