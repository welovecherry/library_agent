from __future__ import annotations
import os
from typing import Any, Dict, List, Optional
import urllib.parse as _urlparse  # ë„ë©”ì¸ ì¶”ì¶œìš©
from datetime import datetime
from pathlib import Path

# Agent ëª¨ë“œìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ (ë¡œì»¬ ë¸Œë¼ìš°ì € ì§ì ‘ ì œì–´)
try:
    from browser_use import Agent, ChatOpenAI, Browser  # type: ignore
except Exception:
    Agent = None  # type: ignore
    ChatOpenAI = None  # type: ignore
    Browser = None  # type: ignore

# .env ìë™ ë¡œë“œ(ìˆìœ¼ë©´)
try:
    from dotenv import load_dotenv  # type: ignore
    load_dotenv()
except Exception:
    pass

try:
    from browser_use_sdk import BrowserUseClient  # type: ignore
except Exception:
    BrowserUseClient = None  # ëŸ°íƒ€ì„ì— ë¯¸ì„¤ì¹˜ë©´ 'ì‹¤í–‰ ê³„íš'ë§Œ ë°˜í™˜í•˜ì—¬ ë””ë²„ê¹… ê°€ëŠ¥

SELECTORS_PATH = "00_src/configs/selectors.yaml"

# Quick SPA readiness keywords for Korean library sites
SPA_READY_KEYWORDS = ["ê²€ìƒ‰ê²°ê³¼", "ì†Œì¥", "ëŒ€ì¶œ", "ê´€ì‹¬ë„ì„œ", "ìƒì„¸ë³´ê¸°"]

def _build_browser_use_task(catalog_home_url: str, title: str, hint: Dict[str, Any], backoff: List[int]) -> str:
    """DOM ì‹ í˜¸ ê¸°ë°˜: ë³´ì´ë©´ ì¦‰ì‹œ ì§„í–‰, ë³´ì´ì§€ ì•Šìœ¼ë©´ ì¶©ë¶„íˆ ëŒ€ê¸° í›„ ì¢…ë£Œ."""
    return f"""
1) navigate to "{catalog_home_url}"
2) if a VISIBLE search input exists (placeholder/aria-label/label text includes: ê²€ìƒ‰|ë„ì„œ|ìë£Œ), DO NOT WAIT: focus it immediately.
   else wait up to 10s for SPA to load; if still hidden, STOP with no_results. DO NOT REFRESH.
3) type "{title}" and press Enter. if not submitted, click the search/ë‹ë³´ê¸° button ONCE (no repeats).
4) if URL changed OR the page contains any of [ê²€ìƒ‰ê²°ê³¼, ì†Œì¥, ëŒ€ì¶œ, ê±´], STOP immediately with success (done).
5) NEVER repeat the same action twice. at most 2 attempts TOTAL. do not open new tabs. do not save HTML.
"""

def search_book(state: Dict[str, Any]) -> Dict[str, Any]:
    """ë„ì„œê´€ í™ˆ ì´ë™ + ì´ˆê°„ë‹¨ ê²€ìƒ‰(ê²Œì´íŠ¸ë“œ LLM). ìº¡ì²˜ëŠ” í•˜ì§€ ì•ŠìŒ."""
    # í•µì‹¬ ì…ë ¥
    home = str(state.get("catalog_home_url", "")).strip()
    title = str(state.get("title", "")).strip()
    place = str(state.get("place", "")).strip()
    if not place:
        # fallback: try to infer later from saved filename; still keep non-empty token for downstream
        place = state["place"] = "unknown"
    if not home or not title:
        return {**state, "ok": False, "result_hint": "invalid_input", "page_url": None}

    # í…”ë ˆë©”íŠ¸ë¦¬ ë¹„í™œì„±(ë¶ˆí•„ìš” ë°±ì˜¤í”„ ë°©ì§€) - ëª¨ë“  ë³€ìˆ˜ ê°•ì œ ì„¤ì •
    os.environ["POSTHOG_DISABLED"] = "1"
    os.environ["ANONYMIZED_TELEMETRY"] = "false"
    os.environ["TELEMETRY_DISABLED"] = "1"
    os.environ["DO_NOT_TRACK"] = "1"

    # ë¸Œë¼ìš°ì € ì œí•œ: í™ˆ URLì—ì„œ ë„ë©”ì¸ ì¶”ì¶œ
    def _derive_allowed_from_home(url: str) -> List[str]:
        try:
            netloc = _urlparse.urlparse(url).netloc
            if netloc and "." in netloc:
                base = netloc.split(":")[0]
                parts = base.split(".")
                if len(parts) >= 2:
                    return [base, f"*.{'.'.join(parts[-2:])}"]
                return [base]
        except Exception:
            pass
        return ["*.go.kr", "*.or.kr"]  # fallback
    
    allowed = state.get("allowed_domains") or _derive_allowed_from_home(home)

    # ë¸Œë¼ìš°ì € ìƒì„±
    browser = None
    if Browser is not None:
        try:
            browser = Browser(
                headless=False,
                allowed_domains=allowed,
                window_size={"width": 1280, "height": 900},
                keep_alive=True,
                minimum_wait_page_load_time=0.5,
                wait_for_network_idle_page_load_time=0.8,
                wait_between_actions=0.2,
                highlight_elements=False,
            )
            print(f"[search_book] Browser ìƒì„± ì™„ë£Œ")
        except Exception as e:
            print(f"[search_book] âŒ Browser ìƒì„± ì‹¤íŒ¨: {e}")
            browser = None

    # LLM (ì†Œí˜• ëª¨ë¸)
    if Agent is None or ChatOpenAI is None:
        # ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¯¸ì„¤ì¹˜ ì‹œ ê³„íšë§Œ ë°˜í™˜
        task_preview = _build_browser_use_task(home, title, {}, [30, 60, 90])
        return {**state, "ok": False, "result_hint": "plan_only", "page_url": None, "log": ["browser_use Agent ë¯¸ì„¤ì¹˜"], "task_prompt": task_preview}
    llm = ChatOpenAI(model=state.get("llm_model", "gpt-5-mini"))

    # 1ë‹¨ê³„: ê·œì¹™ ê¸°ë°˜(ì•„ì£¼ ì§§ì€ íƒœìŠ¤í¬, max_steps=8)
    task_rules = _build_browser_use_task(home, title, {}, [30, 60, 90])
    agent_rules = Agent(task=task_rules, llm=llm, browser=browser) if browser else Agent(task=task_rules, llm=llm)

    import asyncio
    try:
        # asyncio ë‚´ì—ì„œ CDP/URL/HTML ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
        async def run_and_extract():
            history = await agent_rules.run(max_steps=int(state.get("max_steps_rules", 8)))
            
            # SPA ë¡œë”© ì™„ë£Œ ëŒ€ê¸°: ë„¤íŠ¸ì›Œí¬ ì•„ì´ë“¤ + ë³¸ë¬¸ í‚¤ì›Œë“œ ë“±ì¥ ëŒ€ê¸°(ìµœëŒ€ 10s)
            try:
                await browser.wait_for_network_idle(timeout=10000)
            except Exception:
                await asyncio.sleep(1.5)

            # ì¶”ê°€: ë³¸ë¬¸ì— ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²°ê³¼ í‚¤ì›Œë“œê°€ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€ í´ë§(ìµœëŒ€ 10s)
            ready = False
            for _ in range(20):  # 20 * 0.5s = 10s
                try:
                    eval_result = await browser.cdp_client.send.Runtime.evaluate(
                        params={
                            "expression": "document.body ? document.body.innerText : ''",
                            "returnByValue": True
                        },
                        session_id=browser.agent_focus.session_id
                    )
                    body_text = (eval_result.get("result", {}) or {}).get("value", "") or ""
                    if any(k in body_text for k in SPA_READY_KEYWORDS):
                        ready = True
                        break
                except Exception:
                    pass
                await asyncio.sleep(0.5)

            print(f"[search_book] SPA ë¡œë”© ëŒ€ê¸° ì™„ë£Œ ({'ì„±ê³µ' if ready else 'íƒ€ì„ì•„ì›ƒ'})")
            
            # ì¶”ê°€ ëŒ€ê¸°: ê²€ìƒ‰ ê²°ê³¼ ë°ì´í„°ê°€ ì™„ì „íˆ ë¡œë“œë  ì‹œê°„ í™•ë³´ (5ì´ˆ)
            if ready:
                print(f"[search_book] ê²€ìƒ‰ ê²°ê³¼ ë°ì´í„° ë¡œë”© ëŒ€ê¸° ì¤‘... (5ì´ˆ)")
                await asyncio.sleep(5)
            
            # CDP endpoint & page_url ì¶”ì¶œ
            page_url = None
            cdp = None
            
            if browser:
                try:
                    cdp = browser.cdp_url
                    print(f"[search_book] CDP: {cdp}")
                except Exception as e:
                    print(f"[search_book] CDP ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                
                try:
                    page_url = await browser.get_current_page_url()
                    print(f"[search_book] URL: {page_url}")
                except Exception as e:
                    print(f"[search_book] URL ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            
            # HTML ì¶”ì¶œ ë° ì €ì¥
            saved_path = None
            html_size = 0
            
            if browser and hasattr(browser, 'cdp_client') and browser.cdp_client:
                try:
                    print(f"[search_book] HTML ì¶”ì¶œ ì‹œì‘...")
                    result = await browser.cdp_client.send.Runtime.evaluate(
                        params={
                            "expression": "document.documentElement.outerHTML",
                            "returnByValue": True
                        },
                        session_id=browser.agent_focus.session_id
                    )
                    html_content = result.get("result", {}).get("value", "")
                    
                    if html_content:
                        # ì €ì¥ ê²½ë¡œ ìƒì„±
                        today = datetime.now().strftime("%Y-%m-%d")
                        timestamp = int(datetime.now().timestamp())
                        dir_path = f"00_src/data/raw/{today}"
                        os.makedirs(dir_path, exist_ok=True)
                        
                        filename = f"{place}_{timestamp}_results.html"
                        saved_path = os.path.join(dir_path, filename)
                        
                        # íŒŒì¼ ì €ì¥
                        with open(saved_path, "w", encoding="utf-8") as f:
                            f.write(html_content)
                        
                        # ë©”íƒ€ë°ì´í„° ì‚¬ì´ë“œì¹´ ì €ì¥(.meta.json)
                        try:
                            meta = {
                                "place": place,
                                "page_url": page_url,
                                "captured_at": datetime.now().isoformat(timespec="seconds"),
                                "cdp_endpoint": cdp
                            }
                            with open(saved_path + ".meta.json", "w", encoding="utf-8") as mf:
                                import json as _json
                                mf.write(_json.dumps(meta, ensure_ascii=False))
                        except Exception as _e:
                            print(f"[search_book] ë©”íƒ€ ì €ì¥ ê²½ê³ : {_e}")
                        
                        html_size = len(html_content)
                        print(f"[search_book] âœ… HTML ì €ì¥ ì™„ë£Œ (í˜ì´ì§€ 1): {saved_path} ({html_size:,} bytes)")
                    else:
                        print(f"[search_book] âš ï¸ HTML ë‚´ìš©ì´ ë¹„ì–´ìˆìŒ")
                        
                except Exception as e:
                    print(f"[search_book] âŒ HTML ì¶”ì¶œ/ì €ì¥ ì‹¤íŒ¨: {e}")
                    import traceback
                    traceback.print_exc()
            
            # ========== ë‹¤ì¤‘ í˜ì´ì§€ ì²˜ë¦¬: JavaScript ì§ì ‘ ì‹¤í–‰ìœ¼ë¡œ ë§ˆì§€ë§‰ í˜ì´ì§€ê¹Œì§€ ==========
            saved_html_paths = [saved_path]  # 1í˜ì´ì§€ ê²½ë¡œ ì €ì¥
            
            # ê³µí†µ ë³€ìˆ˜ ì¤€ë¹„
            today = datetime.now().strftime("%Y-%m-%d")
            base_timestamp = int(datetime.now().timestamp())
            dir_path = Path(f"00_src/data/raw/{today}")
            
            if browser:
                current_page = 1
                max_pages = 10  # ì•ˆì „ì¥ì¹˜ (ë¬´í•œ ë£¨í”„ ë°©ì§€)
                
                while current_page < max_pages:
                    try:
                        next_page_num = current_page + 1
                        print(f"[search_book] ğŸ” {next_page_num}í˜ì´ì§€ ë²„íŠ¼ ì°¾ëŠ” ì¤‘...")
                        
                        # JavaScriptë¡œ ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ í´ë¦­ (ë‹¤ì¤‘ íŒ¨í„´ ì§€ì›)
                        js_code = f"""
(function() {{
    // íŒ¨í„´ 1: ì†¡íŒŒêµ¬ ìŠ¤íƒ€ì¼ - javascript:fnList(N)
    let link = document.querySelector('a[href*="fnList({next_page_num})"]');
    if (link) {{
        link.click();
        return 'clicked_fnList';
    }}
    
    // íŒ¨í„´ 2: ê°•ë‚¨êµ¬ ìŠ¤íƒ€ì¼ - button.pgNum
    let pgNumButtons = document.querySelectorAll('button.pgNum');
    for (let btn of pgNumButtons) {{
        if (btn.textContent.trim() === '{next_page_num}') {{
            btn.click();
            return 'clicked_pgNum';
        }}
    }}
    
    // íŒ¨í„´ 3: ì„œì´ˆêµ¬ ìŠ¤íƒ€ì¼ - button with @click
    let allButtons = document.querySelectorAll('button');
    for (let btn of allButtons) {{
        if (btn.textContent.trim() === '{next_page_num}') {{
            btn.click();
            return 'clicked_button';
        }}
    }}
    
    // íŒ¨í„´ 4: ì¼ë°˜ ë§í¬ (í…ìŠ¤íŠ¸ê°€ Nì¸ ëª¨ë“  <a> íƒœê·¸)
    let allLinks = document.querySelectorAll('a');
    for (let a of allLinks) {{
        if (a.textContent.trim() === '{next_page_num}' && a.href.includes('javascript')) {{
            a.click();
            return 'clicked_link';
        }}
    }}
    
    return 'not_found';
}})()
"""
                        
                        # JavaScript ì‹¤í–‰
                        result = await browser.cdp_client.send.Runtime.evaluate(
                            params={
                                "expression": js_code,
                                "returnByValue": True
                            },
                            session_id=browser.agent_focus.session_id
                        )
                        
                        click_result = result.get("result", {}).get("value", "not_found")
                        clicked = click_result != "not_found"
                        
                        print(f"[search_book] {'âœ…' if clicked else 'ğŸ“'} {next_page_num}í˜ì´ì§€ í´ë¦­ ê²°ê³¼: {click_result}")
                        
                        if not clicked:
                            # ë‹¤ìŒ ë²„íŠ¼ ì—†ìŒ â†’ ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬
                            print(f"[search_book] ğŸ“ ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬ (í˜„ì¬: {current_page}í˜ì´ì§€)")
                            break
                        
                        current_page = next_page_num
                        
                        # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸° (SPA ì‚¬ì´íŠ¸ë¥¼ ìœ„í•´ ì¶©ë¶„í•œ ì‹œê°„ í™•ë³´)
                        print(f"[search_book] {current_page}í˜ì´ì§€ ë¡œë”© ëŒ€ê¸° ì¤‘... (7ì´ˆ)")
                        await asyncio.sleep(7)
                        
                        # HTML ì¶”ì¶œ
                        print(f"[search_book] {current_page}í˜ì´ì§€ HTML ì¶”ì¶œ ì¤‘...")
                        page_html = await browser.cdp_client.send.Runtime.evaluate(
                            params={
                                "expression": "document.documentElement.outerHTML",
                                "returnByValue": True
                            },
                            session_id=browser.agent_focus.session_id
                        )
                        page_html_content = page_html.get("result", {}).get("value", "")
                        
                        if page_html_content and len(page_html_content) > 1000:
                            # íŒŒì¼ëª… ìƒì„±
                            page_filename = f"{place}_{base_timestamp}_results_page{current_page}.html"
                            page_path = dir_path / page_filename
                            
                            # HTML ì €ì¥
                            page_path.write_text(page_html_content, encoding="utf-8")
                            page_size = len(page_html_content)
                            print(f"[search_book] âœ… {current_page}í˜ì´ì§€ HTML ì €ì¥ ì™„ë£Œ: {page_path} ({page_size:,} bytes)")
                            
                            saved_html_paths.append(str(page_path))
                        else:
                            print(f"[search_book] âš ï¸ {current_page}í˜ì´ì§€ HTML ì¶”ì¶œ ì‹¤íŒ¨ ë˜ëŠ” ë‚´ìš© ë¶€ì¡±")
                            break  # HTML ì¶”ì¶œ ì‹¤íŒ¨í•˜ë©´ ì¤‘ë‹¨
                        
                    except Exception as e:
                        print(f"[search_book] âš ï¸ {current_page}í˜ì´ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                        import traceback
                        traceback.print_exc()
                        break  # ì—ëŸ¬ ë°œìƒ ì‹œ ì¤‘ë‹¨
            
            # ë¸Œë¼ìš°ì € ì¢…ë£Œ (async ì»¨í…ìŠ¤íŠ¸ ë‚´ë¶€ì—ì„œ)
            if browser:
                try:
                    print(f"[search_book] ë¸Œë¼ìš°ì € ì¢…ë£Œ ì¤‘...")
                    await browser.stop()  # BrowserSessionì€ close() ëŒ€ì‹  stop() ì‚¬ìš©
                    print(f"[search_book] âœ… ë¸Œë¼ìš°ì € ì¢…ë£Œ ì™„ë£Œ")
                except Exception as e:
                    print(f"[search_book] âš ï¸ ë¸Œë¼ìš°ì € ì¢…ë£Œ ê²½ê³ : {e}")
            
            return history, page_url, cdp, saved_html_paths, html_size
        
        # asyncio ì‹¤í–‰
        history1, page_url, cdp_endpoint, saved_html_paths, html_size = asyncio.run(run_and_extract())
        
        total_pages = len(saved_html_paths)
        print(f"[search_book] ğŸ“Š ì´ {total_pages}ê°œ í˜ì´ì§€ HTML ì €ì¥ ì™„ë£Œ")
        
        return {
            **state, 
            "ok": True, 
            "result_hint": "results_detected", 
            "page_url": page_url, 
            "cdp_endpoint": cdp_endpoint, 
            "saved_html_path": saved_html_paths[0] if saved_html_paths else None,  # 1í˜ì´ì§€ ê²½ë¡œ (í•˜ìœ„ í˜¸í™˜)
            "saved_html_paths": saved_html_paths,  # ì „ì²´ í˜ì´ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            "total_pages": total_pages,
            "html_size": html_size, 
            "used_frame": None, 
            "markers": [], 
            "log": [f"rules_steps={len(history1) if isinstance(history1, list) else 'unknown'}"], 
            "place": place
        }
    except Exception as e1:
        # 2ë‹¨ê³„: ìœ ì—° íƒœìŠ¤í¬(í•œ ë²ˆë§Œ), max_steps=15
        task_llm = f"ìˆ˜ì •ëœ ì‹œë„: ìœ„ì™€ ë™ì¼í•˜ì§€ë§Œ ë‹¤ë¥¸ ê²½ë¡œë„ í—ˆìš©. ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ ì¢…ë£Œ.\n" + _build_browser_use_task(home, title, {}, [30, 60, 90])
        agent_llm = Agent(task=task_llm, llm=llm, browser=browser) if browser else Agent(task=task_llm, llm=llm)
        try:
            # asyncio ë‚´ì—ì„œ CDP/URL/HTML ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ (LLM ê²½ë¡œ)
            async def run_and_extract_llm():
                history = await agent_llm.run(max_steps=int(state.get("max_steps_llm", 15)))
                
                # SPA ë¡œë”© ì™„ë£Œ ëŒ€ê¸°: ë„¤íŠ¸ì›Œí¬ ì•„ì´ë“¤ + ë³¸ë¬¸ í‚¤ì›Œë“œ ë“±ì¥ ëŒ€ê¸°(ìµœëŒ€ 10s)
                try:
                    await browser.wait_for_network_idle(timeout=10000)
                except Exception:
                    await asyncio.sleep(1.5)

                # ì¶”ê°€: ë³¸ë¬¸ì— ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²°ê³¼ í‚¤ì›Œë“œê°€ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€ í´ë§(ìµœëŒ€ 10s)
                ready = False
                for _ in range(20):  # 20 * 0.5s = 10s
                    try:
                        eval_result = await browser.cdp_client.send.Runtime.evaluate(
                            params={
                                "expression": "document.body ? document.body.innerText : ''",
                                "returnByValue": True
                            },
                            session_id=browser.agent_focus.session_id
                        )
                        body_text = (eval_result.get("result", {}) or {}).get("value", "") or ""
                        if any(k in body_text for k in SPA_READY_KEYWORDS):
                            ready = True
                            break
                    except Exception:
                        pass
                    await asyncio.sleep(0.5)

                print(f"[search_book LLM] SPA ë¡œë”© ëŒ€ê¸° ì™„ë£Œ ({'ì„±ê³µ' if ready else 'íƒ€ì„ì•„ì›ƒ'})")
                
                # ì¶”ê°€ ëŒ€ê¸°: ê²€ìƒ‰ ê²°ê³¼ ë°ì´í„°ê°€ ì™„ì „íˆ ë¡œë“œë  ì‹œê°„ í™•ë³´ (5ì´ˆ)
                if ready:
                    print(f"[search_book LLM] ê²€ìƒ‰ ê²°ê³¼ ë°ì´í„° ë¡œë”© ëŒ€ê¸° ì¤‘... (5ì´ˆ)")
                    await asyncio.sleep(5)
                
                # CDP endpoint & page_url ì¶”ì¶œ
                page_url = None
                cdp = None
                
                if browser:
                    try:
                        cdp = browser.cdp_url
                        print(f"[search_book LLM] CDP: {cdp}")
                    except Exception as e:
                        print(f"[search_book LLM] CDP ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                    
                    try:
                        page_url = await browser.get_current_page_url()
                        print(f"[search_book LLM] URL: {page_url}")
                    except Exception as e:
                        print(f"[search_book LLM] URL ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                
                # HTML ì¶”ì¶œ ë° ì €ì¥
                saved_path = None
                html_size = 0
                
                if browser and hasattr(browser, 'cdp_client') and browser.cdp_client:
                    try:
                        print(f"[search_book LLM] HTML ì¶”ì¶œ ì‹œì‘...")
                        result = await browser.cdp_client.send.Runtime.evaluate(
                            params={
                                "expression": "document.documentElement.outerHTML",
                                "returnByValue": True
                            },
                            session_id=browser.agent_focus.session_id
                        )
                        html_content = result.get("result", {}).get("value", "")
                        
                        if html_content:
                            today = datetime.now().strftime("%Y-%m-%d")
                            timestamp = int(datetime.now().timestamp())
                            dir_path = f"00_src/data/raw/{today}"
                            os.makedirs(dir_path, exist_ok=True)
                            
                            filename = f"{place}_{timestamp}_results.html"
                            saved_path = os.path.join(dir_path, filename)
                            
                            with open(saved_path, "w", encoding="utf-8") as f:
                                f.write(html_content)
                            
                            # ë©”íƒ€ë°ì´í„° ì‚¬ì´ë“œì¹´ ì €ì¥(.meta.json)
                            try:
                                meta = {
                                    "place": place,
                                    "page_url": page_url,
                                    "captured_at": datetime.now().isoformat(timespec="seconds"),
                                    "cdp_endpoint": cdp
                                }
                                with open(saved_path + ".meta.json", "w", encoding="utf-8") as mf:
                                    import json as _json
                                    mf.write(_json.dumps(meta, ensure_ascii=False))
                            except Exception as _e:
                                print(f"[search_book LLM] ë©”íƒ€ ì €ì¥ ê²½ê³ : {_e}")
                            
                            html_size = len(html_content)
                            print(f"[search_book LLM] âœ… HTML ì €ì¥ ì™„ë£Œ: {saved_path} ({html_size:,} bytes)")
                        else:
                            print(f"[search_book LLM] âš ï¸ HTML ë‚´ìš©ì´ ë¹„ì–´ìˆìŒ")
                            
                    except Exception as e:
                        print(f"[search_book LLM] âŒ HTML ì¶”ì¶œ/ì €ì¥ ì‹¤íŒ¨: {e}")
                        import traceback
                        traceback.print_exc()
                
                # ë¸Œë¼ìš°ì € ì¢…ë£Œ (async ì»¨í…ìŠ¤íŠ¸ ë‚´ë¶€ì—ì„œ)
                if browser:
                    try:
                        print(f"[search_book] ë¸Œë¼ìš°ì € ì¢…ë£Œ ì¤‘...")
                        await browser.stop()  # BrowserSessionì€ close() ëŒ€ì‹  stop() ì‚¬ìš©
                        print(f"[search_book] âœ… ë¸Œë¼ìš°ì € ì¢…ë£Œ ì™„ë£Œ")
                    except Exception as e:
                        print(f"[search_book] âš ï¸ ë¸Œë¼ìš°ì € ì¢…ë£Œ ê²½ê³ : {e}")
                
                return history, page_url, cdp, saved_path, html_size
            
            history2, page_url, cdp_endpoint, saved_html_path, html_size = asyncio.run(run_and_extract_llm())
            
            return {**state, "ok": True, "result_hint": "results_detected", "page_url": page_url, "cdp_endpoint": cdp_endpoint, "saved_html_path": saved_html_path, "html_size": html_size, "used_frame": None, "markers": [], "log": [f"llm_steps={len(history2) if isinstance(history2, list) else 'unknown'}", str(e1)], "place": place}
        except Exception as e2:
            return {**state, "ok": False, "result_hint": "execution_error", "page_url": None, "cdp_endpoint": None, "saved_html_path": None, "html_size": 0, "used_frame": None, "markers": [], "log": ["rules_failed", str(e1), "llm_failed", str(e2)]}
