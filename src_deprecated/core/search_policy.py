# LLMì´ â€œë„ì„œê´€ í™ˆí˜ì´ì§€ë¥¼ ìŠ¤ìŠ¤ë¡œ ì°¾ì•„ ë“¤ì–´ê°€ ì±…ì„ ê²€ìƒ‰â€í•  ìˆ˜ ìˆê²Œ í•œë‹¤.

# 00_src/core/search_policy.py
# ëª©ì :
# - ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¥ì†Œ(ì£¼ì†Œ/êµ¬/ë„ì‹œ) + ì±… ì œëª©ìœ¼ë¡œ ê²€ìƒ‰ ì¿¼ë¦¬ë“¤ì„ ë§Œë“¤ê³ 
# - ê²€ìƒ‰ ê²°ê³¼ URL í›„ë³´ë“¤ì— ëŒ€í•´ "ë„ì„œê´€/ê³µê³µì„±" ì ìˆ˜ë¥¼ ë§¤ê²¨ ìµœì  URL/ë„ë©”ì¸ì„ ê³ ë¥¸ë‹¤.
# - ë„ë©”ì¸ë³„ ì–´ëŒ‘í„°(adapters/*.yaml)ê°€ ìˆìœ¼ë©´ ê°€ì‚°ì ì„ ì£¼ê³ , íŒíŠ¸ë¥¼ í•¨ê»˜ ë°˜í™˜í•œë‹¤.
#
# ì´ íŒŒì¼ì€ "ë„¤íŠ¸ì›Œí¬ ìš”ì²­"ì„ ì§ì ‘ í•˜ì§€ ì•ŠëŠ”ë‹¤. (ê²€ìƒ‰/íƒìƒ‰ì€ browser-useê°€ ìˆ˜í–‰)
# ì—¬ê¸°ì„  'ì •ì±…/ìŠ¤ì½”ì–´ë§/íŒíŠ¸ ë¡œë”©'ë§Œ ë‹´ë‹¹í•œë‹¤.

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from urllib.parse import urlparse
import re
import json

try:
    import yaml  # PyYAML (requirements.txtì— ì¶”ê°€ ê¶Œì¥)
except Exception:  # yamlì´ ì—†ìœ¼ë©´ ì–´ëŒ‘í„° ë¡œë”©ë§Œ ë¹„í™œì„±
    yaml = None


# ====== ê²½ë¡œ ê¸°ë³¸ê°’ ======
ROOT = Path(__file__).resolve().parents[1]  # 00_src/
ADAPTER_DIR = ROOT / "configs" / "adapters"

# ====== ìŠ¤ì½”ì–´ë§ ìƒìˆ˜ ======
# ë„ë©”ì¸/ê²½ë¡œ/í…ìŠ¤íŠ¸ íŒíŠ¸ì— ë”°ë¥¸ ê°€ì‚°ì 
SCORES = {
    "domain_suffix": {
        ".go.kr": 8.0,
        ".lib": 6.0,            # ì˜ˆ: something.lib.seoul.kr (ë¶€ë¶„ í¬í•¨ íŒì •)
        "library": 4.0,         # ì˜ˆ: library.* ë„ë©”ì¸
        "splib": 6.0,           # ì˜ˆ: *.splib.or.kr
    },
    "path_keywords": {
        "search": 3.0,
        "catalog": 3.0,
        "integrated": 2.0,
        "plusSearchResultList": 2.5,  # ê°•ë‚¨ ì˜ˆì‹œ
        "ìë£Œ": 2.0,
        "ê²€ìƒ‰": 2.0,
        "ì†Œì¥": 2.0,
    },
    "bad_indicators": {
        "naver": -3.0,
        "blog": -4.0,
        "youtube": -6.0,
        "twitter": -4.0,
        "x.com": -4.0,
        "tistory": -3.0,
        "news": -2.0,
        "map": -2.0,
        "ad": -5.0,
    },
    "adapter_bonus": 5.0,       # ì–´ëŒ‘í„°ê°€ ìˆìœ¼ë©´ ê°€ì‚°
    "title_bonus_if_contains": 1.0,  # URL ë¬¸ìì—´ì— ì±… í‚¤ì›Œë“œê°€ ì¼ë¶€ ë³´ì´ë©´ ì†Œí­ ê°€ì‚°
}

# ê²€ìƒ‰ í‚¤ì›Œë“œ í…œí”Œë¦¿
QUERY_TEMPLATES = [
    "{place} ê³µê³µë„ì„œê´€ í†µí•©ê²€ìƒ‰ {title}",
    "{place} ë„ì„œê´€ ìë£Œê²€ìƒ‰ {title}",
    "{place} êµ¬ë¦½ë„ì„œê´€ ì†Œì¥ {title}",
    "{place} library catalog {title}",
    # ìŠ¤ì½”í”„ ì¢íˆê¸° (ê³µê³µ ë„ë©”ì¸ ìš°ì„ )
    "{place} ë„ì„œê´€ {title} site:go.kr",
    "{place} ë„ì„œê´€ {title} site:or.kr",
    "{place} ë„ì„œê´€ {title} site:lib",
]

# ê²°ê³¼ êµ¬ì¡°ì²´
@dataclass
class DomainChoice:
    url: str
    domain: str
    score: float
    reason: List[str]
    adapter: Optional[Dict] = None  # ë¡œë“œëœ ì–´ëŒ‘í„° íŒíŠ¸


# ========== ìœ í‹¸ ==========

def _normalize_spaces(text: str) -> str:
    return re.sub(r"\s+", " ", text).strip()


def _slugify_for_filename(text: str) -> str:
    # íŒŒì¼ëª…ì— ì“¸ ìˆ˜ ìˆê²Œ ê°„ë‹¨ ì •ê·œí™” (ê³µë°±->_, í•œê¸€/ì˜ë¬¸/ìˆ«ì/._-ë§Œ í—ˆìš©)
    text = _normalize_spaces(text)
    text = re.sub(r"\s+", "_", text)
    text = re.sub(r"[^0-9a-zA-Z._\-\uac00-\ud7a3]", "", text)
    return text


def _domain_contains(domain: str, token: str) -> bool:
    return token in domain.lower()


def _path_contains(path: str, token: str) -> bool:
    return token.lower() in path.lower()


def _load_adapter_for_domain(domain: str) -> Optional[Dict]:
    """
    configs/adapters/{domain}.yaml íŒŒì¼ì´ ìˆìœ¼ë©´ ë¡œë“œ.
    ex) library.gangnam.go.kr.yaml
    """
    if yaml is None:
        return None
    candidate = ADAPTER_DIR / f"{domain}.yaml"
    if candidate.exists():
        try:
            return yaml.safe_load(candidate.read_text(encoding="utf-8")) or {}
        except Exception:
            return None
    return None


# ========== í•µì‹¬ ë¡œì§ ==========

def build_search_queries(place: str, title: str) -> List[str]:
    """ì¥ì†Œ+ì œëª©ìœ¼ë¡œ ë‹¤ì–‘í•œ ì¿¼ë¦¬ ë¬¸ìì—´ ìƒì„±."""
    place = _normalize_spaces(place)
    title = _normalize_spaces(title)
    queries = [tpl.format(place=place, title=title) for tpl in QUERY_TEMPLATES]
    # ì¤‘ë³µ ì œê±° ìœ ì§€ìˆœì„œ
    seen = set()
    uniq = []
    for q in queries:
        if q not in seen:
            uniq.append(q)
            seen.add(q)
    return uniq


def score_candidate_url(url: str, title: str) -> Tuple[float, List[str]]:
    """
    URL ë¬¸ìì—´ë§Œìœ¼ë¡œ ê³µê³µ/ë„ì„œê´€/ì¹´íƒˆë¡œê·¸ ê°€ëŠ¥ì„±ì„ ì ìˆ˜í™”.
    (ì‹¤ì œ í˜ì´ì§€ ë‚´ìš©ì€ browser-useê°€ ë³¸ë‹¤. ì—¬ê¸°ëŠ” 1ì°¨ í•„í„°)
    """
    reasons = []
    score = 0.0
    try:
        parsed = urlparse(url)
        domain = (parsed.netloc or "").lower()
        path_q = (parsed.path + " " + (parsed.query or "")).lower()

        # ë„ë©”ì¸ ê°€ì‚°ì 
        for suffix, s in SCORES["domain_suffix"].items():
            if suffix in domain:
                score += s
                reasons.append(f"+{s} domain has '{suffix}'")

        # ê²½ë¡œ/ì¿¼ë¦¬ í‚¤ì›Œë“œ ê°€ì‚°ì 
        for kw, s in SCORES["path_keywords"].items():
            if _path_contains(path_q, kw):
                score += s
                reasons.append(f"+{s} path contains '{kw}'")

        # ë¶ˆëŸ‰ ì§€í‘œ ê°ì 
        for bad, s in SCORES["bad_indicators"].items():
            if bad in domain or _path_contains(path_q, bad):
                score += s
                reasons.append(f"{s} bad indicator '{bad}'")

        # ì œëª© ì¼ë¶€ê°€ URLì— ë³´ì´ë©´ ì†Œí­ ê°€ì‚°
        if any(tok for tok in title.split() if tok and tok.lower() in url.lower()):
            score += SCORES["title_bonus_if_contains"]
            reasons.append(f"+{SCORES['title_bonus_if_contains']} title token appears in URL")

    except Exception as e:
        reasons.append(f"parse_error: {e}")

    return score, reasons


def choose_best_domain(
    candidates: List[str],
    title: str,
) -> Optional[DomainChoice]:
    """
    ê²€ìƒ‰ì—”ì§„ì—ì„œ ìˆ˜ì§‘ëœ URL í›„ë³´ë“¤ ì¤‘ ìµœì  í›„ë³´ ì„ íƒ.
    - ë„ë©”ì¸ ìŠ¤ì½”ì–´
    - ê²½ë¡œ í‚¤ì›Œë“œ
    - ì–´ëŒ‘í„° ë³´ìœ  ì‹œ ê°€ì‚°
    """
    best: Optional[DomainChoice] = None
    for url in candidates:
        base_score, reasons = score_candidate_url(url, title)
        domain = urlparse(url).netloc.lower()
        adapter = _load_adapter_for_domain(domain)
        if adapter:
            base_score += SCORES["adapter_bonus"]
            reasons.append(f"+{SCORES['adapter_bonus']} adapter exists for {domain}")

        choice = DomainChoice(url=url, domain=domain, score=base_score, reason=reasons, adapter=adapter)
        if (best is None) or (choice.score > best.score):
            best = choice

    return best


def render_agent_hint(choice: DomainChoice) -> Dict:
    """
    browser-useê°€ ë°”ë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ” íŒíŠ¸ ë²ˆë“¤ ìƒì„±.
    - adapterê°€ ìˆìœ¼ë©´ ê·¸ ë‚´ìš©ì„ ìš°ì„  ë°˜ì˜
    - ì—†ìœ¼ë©´ ë¹ˆ íŒíŠ¸ (ììœ¨ íƒìƒ‰)
    """
    hint = {
        "start_url": choice.url,
        "domain": choice.domain,
        "search_hints": {
            "box": [],
            "submit": [],
        },
        "result_hints": {
            "list_candidates": [],
        },
        "labels": {},
        "reason": choice.reason,
        "score": choice.score,
        "adapter_used": bool(choice.adapter),
    }
    if choice.adapter:
        # ì–´ëŒ‘í„° ìŠ¤í‚¤ë§ˆ ì˜ˆ:
        # {
        #   domain: "library.gangnam.go.kr",
        #   search_box_hints: ["#totalSearch", "input[name='keyword']"],
        #   submit_hints: ["#searchBtn"],
        #   result_item_hints: [".result_list li"],
        #   labels: {...}
        # }
        hint["search_hints"]["box"] = choice.adapter.get("search_box_hints", [])
        hint["search_hints"]["submit"] = choice.adapter.get("submit_hints", [])
        hint["result_hints"]["list_candidates"] = choice.adapter.get("result_item_hints", [])
        hint["labels"] = choice.adapter.get("labels", {})

    return hint


# def build_policy(place: str, title: str, engine_order: Optional[List[str]] = None) -> Dict:
#     """
#     browser-use ìƒìœ„ ë ˆì´ì–´ê°€ í˜¸ì¶œí•˜ëŠ” ì§„ì…ì :
#     - ê²€ìƒ‰ ì¿¼ë¦¬ ë¦¬ìŠ¤íŠ¸
#     - ì—”ì§„ ìš°ì„ ìˆœìœ„
#     - URL í›„ë³´ ì„ íƒì„ ìœ„í•œ ìŠ¤ì½”ì–´ë§ ê·œì¹™ ì•ˆë‚´(ë¬¸ì„œìš©)
#     """
#     queries = build_search_queries(place, title)
#     engines = engine_order or ["duckduckgo", "google", "bing"]
#     return {
#         "queries": queries,
#         "engines": engines,
#         "scoring_rules": {
#             "domain_suffix": SCORES["domain_suffix"],
#             "path_keywords": SCORES["path_keywords"],
#             "bad_indicators": SCORES["bad_indicators"],
#             "adapter_bonus": SCORES["adapter_bonus"],
#         },
#     }

def build_policy(place: str, title: str, engine_order: Optional[List[str]] = None) -> Dict:
    """
    browser-use ìƒìœ„ ë ˆì´ì–´ê°€ í˜¸ì¶œí•˜ëŠ” ì§„ì…ì :
    - ê²€ìƒ‰ ì¿¼ë¦¬ ë¦¬ìŠ¤íŠ¸
    - ì—”ì§„ ìš°ì„ ìˆœìœ„ (ìš°ë¦¬ ì •ì±…: DDG only)
    - URL í›„ë³´ ì„ íƒì„ ìœ„í•œ ìŠ¤ì½”ì–´ë§ ê·œì¹™ ì•ˆë‚´(ë¬¸ì„œìš©)
    """
    queries = build_search_queries(place, title)
    # ë¦¬ìº¡ì°¨/ë ˆì´ì•„ì›ƒ ë³€ë™ ìµœì†Œí™”ë¥¼ ìœ„í•´ DuckDuckGoë§Œ ì‚¬ìš©
    engines = ["duckduckgo"]
    return {
        "queries": queries,
        "engines": engines,
        "scoring_rules": {
            "domain_suffix": SCORES["domain_suffix"],
            "path_keywords": SCORES["path_keywords"],
            "bad_indicators": SCORES["bad_indicators"],
            "adapter_bonus": SCORES["adapter_bonus"],
        },
    }

print("ADAPTER_DIR =", ADAPTER_DIR.resolve())
print("EXPECT_FILE =", (ADAPTER_DIR / "library.gangnam.go.kr.yaml").resolve())
print("EXISTS?     =", (ADAPTER_DIR / "library.gangnam.go.kr.yaml").exists())

# ====== (ì„ íƒ) ê°„ë‹¨í•œ ìˆ˜ë™ í…ŒìŠ¤íŠ¸ìš© ======
# ====== (ì„ íƒ) ê°„ë‹¨í•œ ìˆ˜ë™ í…ŒìŠ¤íŠ¸ìš© ======
if __name__ == "__main__":
    """
    Manual smoke test for search policy.

    ëª©ì :
      - 1ë‹¨ê³„(ì¹´íƒˆë¡œê·¸ ì§„ì…)ë¥¼ ê°€ì •í•œ 'ì¥ì†Œ ì „ìš©' ê²€ìƒ‰ ì¿¼ë¦¬ë“¤ì´ ì˜ ìƒì„±ë˜ëŠ”ì§€ í™•ì¸.
      - URL í›„ë³´ ìŠ¤ì½”ì–´ë§ì´ 'ë£¨íŠ¸/ì¹´íƒˆë¡œê·¸ ì§„ì…ìš©' URLì„ ìš°ì„  ì„ íƒí•˜ëŠ”ì§€ í™•ì¸.

    ì£¼ì˜:
      - ê²°ê³¼í˜ì´ì§€ ì „ìš© URL(ì˜ˆ: plusSearchResultList.do?q=...)ì€ ì§ì ‘ í˜¸ì¶œí•˜ë©´ ì‹¤íŒ¨í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ
        í…ŒìŠ¤íŠ¸ í›„ë³´ì—ì„œë„ ë£¨íŠ¸/ì¹´íƒˆë¡œê·¸ ì§„ì…ìš© URLì„ ì‚¬ìš©í•œë‹¤.
    """
    # ì˜ˆì‹œ: place/titleì„ ë„£ë˜, placeë§Œìœ¼ë¡œ SERPë¥¼ ì¹œë‹¤ëŠ” ê°€ì •
    sample = build_policy(place="ê°•ë‚¨êµ¬", title="ìˆ¨ê²°ì´ ë°”ëŒ ë  ë•Œ")
    print(json.dumps(sample, ensure_ascii=False, indent=2))

    # URL í›„ë³´ë¥¼ ê°€ì •í•˜ê³  ìŠ¤ì½”ì–´ë§ í…ŒìŠ¤íŠ¸ (âœ… ë£¨íŠ¸/ì¹´íƒˆë¡œê·¸ ì§„ì… URL ìœ„ì£¼)
    fake_candidates = [
        # ğŸŸ¢ ê°•ë‚¨êµ¬ í†µí•©ë„ì„œê´€ ë£¨íŠ¸(ì§„ì…ìš©, ì•ˆì „)
        "https://library.gangnam.go.kr/intro/index.do",
        # ğŸŸ¢ ì†¡íŒŒ(ì˜ˆ: splib) ê²€ìƒ‰/ì¹´íƒˆë¡œê·¸ë¡œ ë³´ì´ëŠ” ê²½ë¡œ
        "https://www.splib.or.kr/search",
        # ğŸ”´ ì¼ë°˜ í¬í„¸/ë¸”ë¡œê·¸/ë‰´ìŠ¤(ê°ì  ëŒ€ìƒ)
        "https://www.naver.com/search?q=ê°•ë‚¨êµ¬ë¦½ë„ì„œê´€",
        "https://example.com/blog/post",
    ]

    best = choose_best_domain(fake_candidates, title="ìˆ¨ê²°ì´ ë°”ëŒ ë  ë•Œ")
    if best:
        hint = render_agent_hint(best)
        print("\n[Best Choice]")
        print(json.dumps(hint, ensure_ascii=False, indent=2))